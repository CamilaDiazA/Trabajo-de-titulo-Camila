{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95d3aef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten,\\\n",
    " Conv2D, MaxPooling2D,BatchNormalization,LayerNormalization\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.metrics import precision_score,recall_score,accuracy_score, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from skimage.color import (separate_stains, combine_stains,\n",
    "                            hdx_from_rgb, rgb_from_hdx,rgb2hed, hed2rgb)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dde8d9c",
   "metadata": {},
   "source": [
    "# Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afc98dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leer el conjunto de imagenes\n",
    "def LeerImagenes(imagenes):\n",
    "    imgs=[]\n",
    "    for x in range(0,len(imagenes)):\n",
    "        imgs.append(io.imread(imagenes[x]))\n",
    "    MImagenes=np.array(imgs)\n",
    "    \n",
    "    return MImagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "282accb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crea matriz con las etiquetas de las imagenes\n",
    "def CalculoEtiquetas(imagenes):\n",
    "    Etiquetas=[]\n",
    "    for x in range(0,len(imagenes)):\n",
    "        Clasificacion =imagenes[x].split('-') \n",
    "        for i in range(0,len(Clasificacion)) :\n",
    "            Valores=(Clasificacion[2])\n",
    "            Numero=Valores.split('_')\n",
    "        Etiquetas.append(int(Numero[1]))\n",
    "        #Etiquetas=np.array(etiquetas)\n",
    "    return Etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be665f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplico filtro al conjunto de imagenes ingresados cono paramentro\n",
    "def AplicarFiltro(MImagenes):\n",
    "    imgs_con_filtro=[]\n",
    "    for x in range(0,len(MImagenes)):\n",
    "        ihc_hdx = rgb2hed(MImagenes[x])\n",
    "        null = np.zeros_like(ihc_hdx[:, :, 0])\n",
    "        ihc_h = hed2rgb(np.stack((ihc_hdx[:, :, 0], null, null), axis=-1))\n",
    "        ihc_d = hed2rgb(np.stack((null, ihc_hdx[:, :, 1], null), axis=-1))\n",
    "        ihc_x = hed2rgb(np.stack((null, null, ihc_hdx[:, :, 2]), axis=-1))\n",
    "\n",
    "        h = rescale_intensity(ihc_hdx[:, :, 0], out_range=(0, 1),\n",
    "                      in_range=(0, np.percentile(ihc_hdx[:, :, 0], 99)))\n",
    "        d = rescale_intensity(ihc_hdx[:, :, 2], out_range=(0, 1),\n",
    "                      in_range=(0, np.percentile(ihc_hdx[:, :, 2], 99)))\n",
    "    \n",
    "        zdh = np.dstack((null, d, h))\n",
    "        imgs_con_filtro.append(zdh)\n",
    "    Imagenes_con_fitro=np.array(imgs_con_filtro)\n",
    "    return Imagenes_con_fitro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af701d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtiene el canal DAB de las imagenes representativas ingresadas\n",
    "def ImagenDAB(MImagenes):\n",
    "    imgs_DAB=[]\n",
    "    for x in range(0,len(MImagenes)):\n",
    "        ihc_hdx = rgb2hed(MImagenes[x])\n",
    "        null = np.zeros_like(ihc_hdx[:, :, 0])\n",
    "        #Seleccionó solo el canal DAB\n",
    "        ihc_x = hed2rgb(np.stack((null, null, ihc_hdx[:, :, 2]), axis=-1)) \n",
    "        #Guardo solo el canal DAB \n",
    "        imgs_DAB.append(ihc_x)\n",
    "    Imagenes_DAB=np.array(imgs_DAB)\n",
    "    return Imagenes_DAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e0d0ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtiene los valores promedios de cada clase y los valores min y max de estos, segun las imagenes representativas ingresadas\n",
    "\n",
    "def CalculoPromedios(Imagenes_DAB,Etiquetas):\n",
    "    Prom0=[]\n",
    "    Prom1=[]\n",
    "    Prom2=[]\n",
    "    Prom3=[]\n",
    "    Prom_imgs=[]\n",
    "    for x in range(0,len(Imagenes_DAB)):\n",
    "        Promedio=np.mean(Imagenes_DAB[x])\n",
    "        Prom_imgs.append(Promedio)\n",
    "    for x in range(0,len(Etiquetas)):\n",
    "        if Etiquetas[x]==0:\n",
    "            Prom0.append(Prom_imgs[x])\n",
    "        elif Etiquetas[x]==1:\n",
    "            Prom1.append(Prom_imgs[x])\n",
    "        elif Etiquetas[x]==2:\n",
    "            Prom2.append(Prom_imgs[x])\n",
    "        elif Etiquetas[x]==3:   \n",
    "            Prom3.append(Prom_imgs[x])\n",
    "        else:\n",
    "            print(\"Error en la etiqueta\") \n",
    "    Min0=min(Prom0)        \n",
    "    Max0=max(Prom0)\n",
    "    Min1=min(Prom1)\n",
    "    Max1=max(Prom1)\n",
    "    Min2=min(Prom2)\n",
    "    Max2=max(Prom2)\n",
    "    Min3=min(Prom3)\n",
    "    Max3=max(Prom3)\n",
    "    return Min0,Max0,Min1,Max1,Min2,Max2,Min3,Max3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c56728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtra, quitando las imagenes que no cumplan con los valores asignados para su clase, retornando el conjunto de imagenes que \n",
    "#cumplen con los requisitos\n",
    "\n",
    "def SemiFiltro(Imagenes,Etiquetas,Min0,Max0,Min1,Max1,Min2,Max2,Min3,Max3):\n",
    "    Imgs=[]\n",
    "    etqs=[]\n",
    "    Imgs_DAB=ImagenDAB(Imagenes)\n",
    "            \n",
    "    for x in range(0,len(Imagenes)):\n",
    "        Promedio=np.mean(Imgs_DAB[x])\n",
    "        if Etiquetas[x]==0:\n",
    "            if Promedio>=Min0 and Promedio<=Max0:\n",
    "                Imgs.append(Imagenes[x])\n",
    "                etqs.append(Etiquetas[x])\n",
    "        elif Etiquetas[x]==1:\n",
    "            if Promedio>=Min1 and Promedio<=Max1:\n",
    "                Imgs.append(Imagenes[x])\n",
    "                etqs.append(Etiquetas[x])\n",
    "        elif Etiquetas[x]==2:\n",
    "            if Promedio>=Min2 and Promedio<=Max2:\n",
    "                Imgs.append(Imagenes[x])\n",
    "                etqs.append(Etiquetas[x])\n",
    "        elif Etiquetas[x]==3:   \n",
    "            if Promedio>=Min3 and Promedio<=Max3:\n",
    "                Imgs.append(Imagenes[x])\n",
    "                etqs.append(Etiquetas[x])\n",
    "        else:\n",
    "            print(\"Error en la etiqueta\")\n",
    "    Imagenes=np.array(Imgs)\n",
    "    Etqs=np.array(etqs)\n",
    "    return Imagenes,Etqs    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97856bdd",
   "metadata": {},
   "source": [
    "# PREPROCESAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e56418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constantes\n",
    "data_source = \"../data(1000)/\"\n",
    "models_dir = '../saved_models/'\n",
    "train_imgs = glob(f\"{data_source}training/*.png\")\n",
    "test_imgs = glob(f\"{data_source}test/*.png\")\n",
    "I_representativas=glob(f\"{data_source}Imagenes_representativas/*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e3e7c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#leer imagenes\n",
    "Imagenes_rep=LeerImagenes(I_representativas)\n",
    "Etiquetas_rep=CalculoEtiquetas(I_representativas)\n",
    "X_train=LeerImagenes(train_imgs)\n",
    "y_train=CalculoEtiquetas(train_imgs)\n",
    "X_test=LeerImagenes(test_imgs)\n",
    "y_test=CalculoEtiquetas(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7c7a8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImagenesDAB=ImagenDAB(Imagenes_rep)\n",
    "Min0,Max0,Min1,Max1,Min2,Max2,Min3,Max3=CalculoPromedios(ImagenesDAB,Etiquetas_rep)\n",
    "Train_X_final,Train_Y_final=SemiFiltro(X_train,y_train,Min0,Max0,Min1,Max1,Min2,Max2,Min3,Max3)\n",
    "Test_X_final,Test_Y_final=SemiFiltro(X_test,y_test,Min0,Max0,Min1,Max1,Min2,Max2,Min3,Max3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9337be9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265\n",
      "1143\n"
     ]
    }
   ],
   "source": [
    "print(len(Test_X_final))\n",
    "print(len(Train_X_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a3a9e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 4\n",
    "Y_train = np_utils.to_categorical(Train_Y_final, n_classes)\n",
    "Y_test = np_utils.to_categorical(Test_Y_final, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175a1d9d",
   "metadata": {},
   "source": [
    "# Creación de CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "229a1b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 73, 73, 96)        34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 73, 73, 96)        384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 36, 36, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 36, 36, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 36, 36, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 17, 17, 384)       885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 17, 17, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 17, 17, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 17, 17, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 17, 17, 256)       884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 17, 17, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              67112960  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 16388     \n",
      "=================================================================\n",
      "Total params: 87,663,364\n",
      "Trainable params: 87,660,612\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(300,300,3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6392f006",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"logs\\\\fit\\\\\")\n",
    "def get_run_logdir():\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "run_logdir = get_run_logdir()\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb2360fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.optimizers.SGD(lr=0.001), metrics=['accuracy'])\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=tf.optimizers.SGD(lr=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95bf71e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 1/36 [..............................] - ETA: 0s - loss: 4.9516 - accuracy: 0.1562WARNING:tensorflow:From C:\\Users\\camii\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "36/36 [==============================] - 62s 2s/step - loss: 1.8909 - accuracy: 0.4882 - val_loss: 15.2267 - val_accuracy: 0.2981\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 1.0900 - accuracy: 0.6833 - val_loss: 7.8062 - val_accuracy: 0.2981\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.9631 - accuracy: 0.7113 - val_loss: 4.7015 - val_accuracy: 0.2906\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.7287 - accuracy: 0.7673 - val_loss: 2.3783 - val_accuracy: 0.2453\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.7547 - accuracy: 0.7787 - val_loss: 2.6676 - val_accuracy: 0.2981\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.5069 - accuracy: 0.8250 - val_loss: 2.2385 - val_accuracy: 0.5170\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.4353 - accuracy: 0.8644 - val_loss: 2.7812 - val_accuracy: 0.4868\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.4220 - accuracy: 0.8600 - val_loss: 8.7222 - val_accuracy: 0.2981\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.4732 - accuracy: 0.8478 - val_loss: 2.9413 - val_accuracy: 0.6340\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.4803 - accuracy: 0.8399 - val_loss: 5.6798 - val_accuracy: 0.4491\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.3582 - accuracy: 0.8723 - val_loss: 3.6032 - val_accuracy: 0.5170\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.4114 - accuracy: 0.8600 - val_loss: 1.2574 - val_accuracy: 0.5509\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.2815 - accuracy: 0.8968 - val_loss: 0.9991 - val_accuracy: 0.7547\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.3612 - accuracy: 0.8854 - val_loss: 1.9835 - val_accuracy: 0.6642\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.2586 - accuracy: 0.9090 - val_loss: 1.5578 - val_accuracy: 0.6906\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.2339 - accuracy: 0.9134 - val_loss: 2.1528 - val_accuracy: 0.6717\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.2632 - accuracy: 0.9134 - val_loss: 0.8403 - val_accuracy: 0.7472\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.2928 - accuracy: 0.8924 - val_loss: 0.6809 - val_accuracy: 0.7547\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.2424 - accuracy: 0.9178 - val_loss: 0.7120 - val_accuracy: 0.6830\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.2292 - accuracy: 0.9248 - val_loss: 2.6219 - val_accuracy: 0.6340\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.1994 - accuracy: 0.9265 - val_loss: 0.3357 - val_accuracy: 0.8717\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.2376 - accuracy: 0.9143 - val_loss: 4.0709 - val_accuracy: 0.5698\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.1759 - accuracy: 0.9344 - val_loss: 1.6540 - val_accuracy: 0.6717\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.2161 - accuracy: 0.9178 - val_loss: 2.7225 - val_accuracy: 0.4642\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.2449 - accuracy: 0.9265 - val_loss: 1.8507 - val_accuracy: 0.5321\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.1948 - accuracy: 0.9291 - val_loss: 0.3278 - val_accuracy: 0.8377\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.1469 - accuracy: 0.9458 - val_loss: 0.3436 - val_accuracy: 0.8679\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.1582 - accuracy: 0.9449 - val_loss: 2.5062 - val_accuracy: 0.6340\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.1794 - accuracy: 0.9379 - val_loss: 3.2714 - val_accuracy: 0.5321\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.1412 - accuracy: 0.9466 - val_loss: 0.7049 - val_accuracy: 0.6981\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.1254 - accuracy: 0.9536 - val_loss: 1.8800 - val_accuracy: 0.6453\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.1527 - accuracy: 0.9423 - val_loss: 0.3965 - val_accuracy: 0.8377\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.1253 - accuracy: 0.9536 - val_loss: 0.6614 - val_accuracy: 0.7774\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.1254 - accuracy: 0.9519 - val_loss: 1.5799 - val_accuracy: 0.6302\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.1084 - accuracy: 0.9615 - val_loss: 2.9863 - val_accuracy: 0.6340\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.1002 - accuracy: 0.9615 - val_loss: 2.1850 - val_accuracy: 0.7057\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.1499 - accuracy: 0.9361 - val_loss: 2.0098 - val_accuracy: 0.6755\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 63s 2s/step - loss: 0.1461 - accuracy: 0.9458 - val_loss: 1.6652 - val_accuracy: 0.7396\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 63s 2s/step - loss: 0.1205 - accuracy: 0.9519 - val_loss: 0.2946 - val_accuracy: 0.8755\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 62s 2s/step - loss: 0.0846 - accuracy: 0.9668 - val_loss: 0.4230 - val_accuracy: 0.8453\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.1006 - accuracy: 0.9580 - val_loss: 1.5435 - val_accuracy: 0.6528\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.1225 - accuracy: 0.9624 - val_loss: 3.5480 - val_accuracy: 0.5925\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.1178 - accuracy: 0.9519 - val_loss: 1.0022 - val_accuracy: 0.7774\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.0966 - accuracy: 0.9676 - val_loss: 0.3829 - val_accuracy: 0.8377\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 62s 2s/step - loss: 0.0804 - accuracy: 0.9685 - val_loss: 1.3921 - val_accuracy: 0.7660\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.0840 - accuracy: 0.9676 - val_loss: 0.6518 - val_accuracy: 0.7585\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.1051 - accuracy: 0.9659 - val_loss: 0.8805 - val_accuracy: 0.7057\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.1213 - accuracy: 0.9571 - val_loss: 0.5515 - val_accuracy: 0.8038\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 62s 2s/step - loss: 0.1188 - accuracy: 0.9606 - val_loss: 3.4967 - val_accuracy: 0.5660\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.0899 - accuracy: 0.9668 - val_loss: 3.0084 - val_accuracy: 0.6604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16804820ee0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Train_X_final, Y_train, epochs=50,validation_data=(Test_X_final, Y_test),validation_freq = 1,callbacks = [tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "233eebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred=model.predict(Test_X_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1e03cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 65  0  0]\n",
      " [ 0 53  6  0]\n",
      " [ 0 19 43  0]\n",
      " [ 0  0  0 79]]\n"
     ]
    }
   ],
   "source": [
    "cnf_matrix = confusion_matrix(Y_test.argmax(axis=1), Y_test.argmax(axis=1))\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3e9bde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATIAAAEGCAYAAADmLRl+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAg4ElEQVR4nO3deZgU1b3/8fd3FgRFNgdwWAQ0RAURROJGgsaFgLlXjLsxPmjMQ3ITl3ijBu9jzNXcmx8xMbm5xpgQNWLihoqCy1WRSFxBmVGQTXEBBMaBYUdAmJnv74+ugQaH6e7prqmuns8rTz1dVd1z6lt258upU6fOMXdHRCTOiqIOQEQkW0pkIhJ7SmQiEntKZCISe0pkIhJ7JVEHkKysrMz79OkbdRg5N3fZuqhDCM3gPl2iDkEysGzZUmpqaiybMoo79HGv3ZbWZ33bmufdfVQ2x0tHXiWyPn368trsOVGHkXM9r3go6hBC89o9F0cdgmRg+PHDsi7Da7ez3xEXpfXZ7W/fUZb1AdOQV4lMRGLAAMuqUpdzSmQikjnLr+Z1JTIRyZxqZCISbwZFxVEHsQclMhHJjKFLSxGJO9OlpYgUANXIRCT2VCMTkXgz1chEJOYM3bUUkbhTjUxECkGR2shEJM7Uj0xECoLuWopIvOkRJREpBLq0FJFYMz2iJCKFQDUyEYk91chEJN7yr0NsfkUjIvmv4RGldJamijE73MzeSVo2mdmPzayLmU03syXBa+dUIbW6GtmLry/kxtsfo66+nkvHnMS1l42MOqRm69CulN9cdhyH9+yEu/OT+2Zz8sByvj3iMNZt/hyACVPm8o93qyKONDuF9J0li+955aZG5u7vAUMAzKwYWAk8AYwHZrj7BDMbH2z/tKmyQk1kZjYK+D1QDNzt7hPCPF4qdXX1XH/bZJ74w5X06N6JU8f+mtEjBnHEoeVRhtVst158LC/Nr2LcXa9RWlxEuzbFnDywnL9Mf48/P7846vByotC+swaxP6/ct5GdBnzo7svMbAxwSrB/EjCTFIkstEvLIMPeCYwGBgAXm9mAsI6XjooFSzm0dxl9e5XRprSEc84YyrP/nBdlSM3Wvm0Jx3+5Kw+98hEAO+vq2bRtZ8RR5V4hfWfJYn9eVpTeAmVmNidpGbePEi8CGiaA7e7uVQDBa7dU4YRZIzsO+MDdPwIws4eBMcDCEI/ZpKo1G+nZfffldo/unamYvzSqcLLSp2t71m7+nN9993gG9O7MvKXruPmhCgAuP7U/553Yj3nL1nHrI5Vs3BrfBFdI31my2J9X+jWyGndvclZgM2sDnAXc2Nxwwmzs7wl8krS9ItgXGXf/wr48u4uctuKiIgb16cz9L33AN255jq07arnyzAHcP/MDThr/NCNv+T9Wb9jGzRcOjTrUrBTSd5Ys1udllkmNLB2jgUp3rw62q82sPHEoKwdWpyogzETW2NfyhW/PzMY1VDvX1KwJMRzo0a0TK6vX79peVb2eg8s6hnrMsFSt30rV+q28/fFaAJ6Z8wmD+nSmZtN26t1xhwde/pAh/bpEHGl2Cuk7Sxb387KiorSWNF3M7stKgGnA2GB9LDA1VQFhJrIVQO+k7V7Aqr0/5O4T3X2Yuw/rWtY1xHBg6IA+fLh8DctW1rBjZy1TplcyesTRoR4zLGs2bWfVuq0c1v1AAL56ZHfeX7WJbh3b7vrM6KG9eG/lxqhCzIlC+s6Sxfm8DDCztJaUZZntD5wBTEnaPQE4w8yWBO+lvEkYZhvZW0B/M+tH4rbqRcC3QzxeSiUlxdx2wwWce/Wd1NU5l5x1AkceFpO7RI342YMV3DHuREqLi1les4V/v3cWv/j2sQzo3Rl3WLF2Cz+9/62ow8xKoX1nDWJ9Xkbj11vN4O5bgYP22reWxF3MtIWWyNy91syuBJ4n0f3iXndfENbx0jVy+EBGDh8YdRg5seCTDZz5ixf22Hf13bMiiiY8hfSdJYvveaVX22pJofYjc/dngWfDPIaItLxWlchEpDAVpd+Q3yKUyEQkMzlsI8sVJTIRyYi1tjYyESlMSmQiEntKZCISe0pkIhJvBqaZxkUkztTYLyIFQYlMROIvv/KYEpmIZMhUIxORAqBEJiKxZpietRSRApBfFTIlMhHJkNrIRKQQ5Fsiy68LXRGJhRyO2d/JzB4zs8VmtsjMTjSzLmY23cyWBK+dU5WjRCYiGbMiS2tJw++B59z9CGAwsAgYD8xw9/7AjGC7SUpkIpKRdGtjqWpkZtYBGAHcA+DuO9x9A4mJvCcFH5sEnJ0qJiUyEclYji4tDwXWAH81s7fN7G4zOwDo7u5VAMFrt1QFKZGJSMYySGRlDRNwB8u4pGJKgKHAXe5+DPAZaVxGNkZ3LVvAYYfHZL7CZti4dWfUIYSi4/6lUYeQ39K/aVnj7sP28d4KYIW7zw62HyORyKrNrNzdq8ysHFid6iCqkYlIxnJxaenunwKfmNnhwa7TgIXANGBssG8sMDVVPKqRiUhGzKAodwMrXgU8YGZtgI+Ay0lUsCab2RXAcuD8VIUokYlIhnI3sKK7vwM0dul5WiblKJGJSMbyrGO/EpmIZC7fHlFSIhORzJhqZCISc0ZOG/tzQolMRDKmRCYi8aZLSxGJO0ON/SISe5qgV0QKQJ7lMSUyEclQbh9RygklMhHJiNrIRKQg5FkeUyITkcypRiYisZdneUyJTEQypAl6RSTuDNNdSxGJvzyrkCmRiUjmdGkpIvGmh8ZFJO5y2SHWzJYCm4E6oNbdh5lZF+ARoC+wFLjA3dc3VU6rS2Qvvr6QG29/jLr6ei4dcxLXXjYy6pCy8sj3T2Dbjlrq6qHOnXH3V3DFV/vy1S+VUe+wYesOfvl/i1m7ZUfUoTbbxs3bGP/rh3nv408x4LafXsyxR/WNOqysxfm3mONLy6+7e03S9nhghrtPMLPxwfZPmyogtERmZvcC/wKsdvejwjpOJurq6rn+tsk88Ycr6dG9E6eO/TWjRwziiEPjPYHuNQ/PZeO23RPlPvTmJ9zz6lIAzh3ak8tO6svtL7wfUXTZu+WOKZx83JHcdevl7NhZy7bt8Z8UOO6/xZDvWo4BTgnWJwEzSZHIwpyg9z5gVIjlZ6xiwVIO7V1G315ltCkt4ZwzhvLsP+dFHVbObd1Rt2u9bWkx7h5hNNnZ/Nl23pz7ERd+83gA2pSW0PHAdhFHlb1Y/xaDNrJ0FqDMzOYkLeP2Ks2BF8ysIum97u5eBRC8dksVUmg1Mnd/2cz6hlV+c1St2UjP7p13bffo3pmK+UujCygX3Ln9gqNxh2lzV/HU3CoAvve1fowa2J0tn9dxzcPvRBtjFpavWstBndpz3YSHWPTBKgYd3oufX/Ut9m+3X9ShZSXOv0XLbDyyGndvbN7KBsPdfZWZdQOmm9ni5sQUZo0sLWY2riFbr6lZE+qxGquZ5Nvdl0z98MG3+d6kCq5/bB7fOqYng3t1BODuVz7mvD/NYvrCas4Z2jPiKJuvrq6O+UtW8J0xw3n2nuto17YNdz04I+qwshb332IGNbImufuq4HU18ARwHFBtZuWJ41g5sDpVOZEnMnef6O7D3H1Y17KuoR6rR7dOrKzeffNjVfV6Di7rGOoxw9bQiL9h605eWVLDkeUd9nj/xUXVnPzlcP+7hungrp04uGtHjhnQB4AzTx7M/PdXRBxV9uL+WywyS2tpipkdYGYHNqwDI4H5wDRgbPCxscDUlPFkdTYxM3RAHz5cvoZlK2vYsbOWKdMrGT3i6KjDara2pUW0a1O8a/0rfTvzUc1n9Oq8uw1p+JfKWL5ua1QhZq3bQR3o0bUTHy5P/KP8WuUS+vc9OOKoshfn36IFAyums6TQHXjVzOYCbwLPuPtzwATgDDNbApwRbDepVXW/KCkp5rYbLuDcq++krs655KwTOPKweNwlakzn/dvw399K3BAuLjJeXFjNmx+v4xdjBtK7y/64O59u2h7rO5YA/3nNufz4v/7Gzp119O5xEL8Zf3HUIWUt7r/FXNy0dPePgMGN7F8LnJZJWWF2v3iIxC3UMjNbAfzc3e8J63jpGjl8ICOHD4w6jJyo2rid79435wv7fzZ1QQTRhGdg/548NfEnUYeRc3H+LcbmESUzu4PErdFGufvVTRXs7vH/Z1NEGpVneazJGtkX/6kXkVbPSHTByCf7TGTuPil528wOcPfPwg9JRPJdng1HlvqupZmdaGYLgUXB9mAz+2PokYlIfrL07li25OCL6XS/+B/gG8BaAHefC4wIMSYRyWNGbvqR5VJady3d/ZO97lLU7euzIlL44tTY3+ATMzsJcDNrA1xNcJkpIq1TvnW/SOfS8gfAj4CewEpgSLAtIq1Qus9ZtmSuS1kjCwY8u6QFYhGRmCiOW43MzA41s6fMbI2ZrTazqWZ2aEsEJyL5yczSWlpKOpeWDwKTgXKgB/Ao8FCYQYlI/krctUxvaSnpJDJz97+5e22w/J0mHl0SkQKXZm2sJWtkTT1r2SVYfSmYAOBhEgnsQuCZFohNRPJUnjWRNdnYX0EicTWE/P2k9xz4RVhBiUh+y7fuF009a9mvJQMRkXgwEuPf5ZO0evab2VHAAKBtwz53vz+soEQkv+VXGksjkZnZz0kMkDgAeBYYDbwKKJGJtEJmtOhzlOlI567leSSGnf3U3S8nMTRtvOfiEpGs5FvP/nQS2TZ3rwdqzawDiamZ1CFWpBXLZfcLMys2s7fN7Olgu4uZTTezJcFr51RlpJPI5phZJ+AvJO5kVpKY8UREWqkc18iuYc+BKMYDM9y9PzAj2G5SykTm7j909w3u/icSUzONDS4xRaQVMjOKi9Jb0iirF/BN4O6k3WOAhhGqJwFnpyqnqQ6xQ5t6z90rU0YpIgUpg35kZWaWPP/HRHefmLT9P8ANwIFJ+7q7exWAu1eZWbdUB2nqruXtTbznwKmpCpeEOy4cEnUIoblu2sKoQwjFXy76wnSLkiSDmb1r3H1YY2+Y2b8Aq929wsxOySaepjrEfj2bgkWkMBk569k/HDjLzM4k0Ue1g5n9Hag2s/KgNlZO4gZjkzJIrCIiCbkY/cLdb3T3Xu7eF7gI+Ie7fweYBowNPjYWmJoqntBmGheRwmQW+iNKE4DJZnYFsBw4P9UfKJGJSMZyncfcfSYwM1hfS6ITfvrxpPqAJXzHzG4Otg8xs+MyD1VECkUce/b/ETgRuDjY3gzcGVpEIpLX4jqv5fHuPtTM3gZw9/XBtHAi0krl213CdBLZTjMrJhje2sy6AvWhRiUieS3PBr9IK5H9L/AE0M3M/pvEaBg3hRqViOSthkeU8kk681o+YGYVJO4iGHC2u2umcZFWLM/yWFoDKx4CbAWeSt7n7svDDExE8lNDY38+SefS8hl2T0LSFugHvAcMDDEuEcljeZbH0rq0HJS8HYyK8f19fFxECl0LT76bjox79rt7pZl9JYxgRCQeLM+mH0mnjezfkzaLgKHAmtAiEpG8ZkBJnnUkS6dGljzgWS2JNrPHwwlHROIgNhP0QmJSAKC9u1/fQvGISJ5L3LWMOoo9NTXUdYm71zY15LWItEIt/EB4Opqqkb1Joj3sHTObBjwKfNbwprtPCTk2EclTcexH1gVYS2KM/ob+ZA4okYm0QgYUx6ixv1twx3I+uxNYAw81KhHJY0ZRjLpfFAPtodGIlchEWqnE5CNRR7GnphJZlbvf2mKRtJAXX1/Ijbc/Rl19PZeOOYlrLxsZdUjN9qs7p/BGxXt06ngA9/3uagA+WFrFbydOY9v2HRzctRM3XXM+B+zfNuJIm8cMbhr5ZTZs3ckdr3zMmEEHM6RnB9xh0+e1/HXWcjZur406zGaL7W8xRz37zawt8DKwH4lc9Ji7/9zMugCPAH2BpcAF7r6+qbKautLNKlQz621mL5nZIjNbYGbXZFNeLtTV1XP9bZN59Pc/ZNbkm3j8hQoWf1QVdVjNNurrx3DbTWP32Pfru55k3CUj+etvr+Jrxw3g4amvRhRd9k7/chlVm7bv2n5+0Wpuee59bn3+feat3MS/HtU9wuiyE/ffYo5GiP0cONXdBwNDgFFmdgIwHpjh7v2BGcF20/E08V5Gg/83ohb4ibsfCZwA/MjMBmRZZlYqFizl0N5l9O1VRpvSEs45YyjP/nNelCFlZfCAfhzYvt0e+z5ZVcPgAX0BGDb4MF6evSCCyLLXuV0pg3p04NUP1+3at71293ie+5UU4TFu4Ijzb7Hh0jLbMfs9YUuwWRosDowBJgX7JwFnp4ppn4nM3dft6710uHuVu1cG65uBRUDPbMrMVtWajfTs3nnXdo/unalaszHCiHKvX+9uvPbWYgBmvrGA1TXxPL8Lh/bgsXeqqN+rOfbsQQfzq7OO5Pg+nZg6/9OIoste3H+LxUWW1gKUmdmcpGVccjlmVmxm75CYhHe6u88Gurt7FSTyCNAtVTwtchPVzPoCxwCzG3lvXMNJrqkJ9xFOb+Sf8HxrtMzWDT86hyefm8W4G/7I1m2fU1pSHHVIGTu6x4Fs2l7L8vXbvvDek+9+yk+nLWL2sg2c2r8sguhyI86/RSORONJZgBp3H5a0TEwuy93r3H0I0As4zsyOak5Moc9raWbtSTyb+WN337T3+8GJTQQ49thhoV4s9OjWiZXVu9sMV1Wv5+CyjmEessX16dmV39x8OZC4zJxV+V7EEWXusLIDGNKzA4N6dKC0yGhbWswVJxzCPbN2j+U5e9l6rh7Rj2nzqyOMtPli/Vu03D9r6e4bzGwmMAqoNrNyd68ys3IStbUmhVojM7NSEknsgXx4EmDogD58uHwNy1bWsGNnLVOmVzJ6xNFRh5VT6zcmmhzq6+v522MzOeuM+E1B+sS8T7lh2iJufGoRE99YxnvVW7hn1nK6td89edeQnh35dPPnEUaZnbj/Fi3NpckyzLqaWadgvR1wOrAYmAY03MUaC0xNFU9oNTJLpOx7gEXu/tuwjpOJkpJibrvhAs69+k7q6pxLzjqBIw8rjzqsZrv1d4/wzoKP2bh5K+eNu43LLzyVbdt38ORziSv4rx0/gNGnFs6jsucMLufgA/fDgbWf7eDvc1ZEHVKzxfm3mMOhrsuBScHgFEXAZHd/2szeACab2RXAcuD8VAWFeWk5HLgUeDdozAP4D3d/NsRjpjRy+EBGDi+MUbpvvvbCRvef982TWjiS8Ly/+jPeX/0xAH96bVnE0eRWnH+LuUhj7j6PRNv53vvXkmGvidASmbu/Sm7OV0TyilGUZ+P4hN7YLyKFpeGuZT5RIhORjMVqhFgRkcbkVxpTIhORTIXQjyxbSmQikhEDipXIRCTu8iuNKZGJSDPkWYVMiUxEMpPofpFfmUyJTEQyphqZiMScYaqRiUic6a6liMRfzGYaFxFplBKZiMSe2shEJNYSAytGHcWelMhEJGM5GiE2Z5TIRCRjurQUkVjLx0vLfBvoUUTynqX9vyZLMettZi+Z2SIzW2Bm1wT7u5jZdDNbErx2brIglMhEJFNBP7J0lhRqgZ+4+5HACcCPzGwAMB6Y4e79gRnBdpOUyEQkY7mY19Ldq9y9MljfDCwCegJjgEnBxyYBZ6eKR21kLWBwn05RhxCavxTouXX+ypVRhxCKz99bnvpDKWT4iFKZmc1J2p7o7hO/UKZZXxJTw80Gurt7FSSSnZl1S3UQJTIRyVz6jf017j6syaLM2gOPAz92903NGUZbl5YikrFcNPYDmFkpiST2gLtPCXZXm1l58H45sDpVOUpkIpKxXDT2W6LqdQ+wyN1/m/TWNGBssD4WmJoqHl1aikjGctSNbDhwKfCumb0T7PsPYAIw2cyuAJYD56cqSIlMRDKXg0zm7q82UdJpmZSlRCYiGTHTs5YiUgDyK40pkYlIc+RZJlMiE5EMafIRESkAedZEpkQmIpkxlMhEpADo0lJEYk81MhGJvTzLY0pkIpKhdAYba2FKZCKSMbWRiUis5ePkI0pkIpI5JTIRiTtdWopI7Kn7hYjEXp7lMSUyEWmGPMtkrS6Rvfj6Qm68/THq6uu5dMxJXHvZyKhDyplCPbdCOa8v9enGvb/87q7tPj0O4v9NfIZX5yzh9vEX0X7//VhetZZxP5vE5s+2Rxhp0/JxYMXQJh8xs7Zm9qaZzQ2mQ78lrGOlq66unutvm8yjv/8hsybfxOMvVLD4o6qow8qJQj23QjqvD5atZsQlExhxyQROufRXbPt8J8+8NJff3/RtbrlzKsMv/iVPvzSXqy7NaJTnSORigl4AM7vXzFab2fykfV3MbLqZLQleO6cqJ8xZlD4HTnX3wcAQYJSZnRDi8VKqWLCUQ3uX0bdXGW1KSzjnjKE8+895UYaUM4V6boV6Xid/5XCWrljDJ5+u50uHdOP1yg8AmPnmYv7160OiDS4ducpkcB8waq9944EZ7t4fmBFsNym0ROYJW4LN0mDxsI6Xjqo1G+nZfXdy79G9M1VrNkYYUe4U6rkV6nmdM/JYHn++AoDFH1UxesQgAMacNnSP881P6c5qmTqTufvLwLq9do8BJgXrk4CzU5UT6ryWZlYcTPO0Gpju7rPDPF4q7l/Mo3l2qd9shXpuhXhepSXFjB4xiCdnvA3Albc+wPfOH8FL999A+/33Y+fOuogjTC2DeS3LzGxO0jIujeK7u3sVQPDaLdUfhNrY7+51wBAz6wQ8YWZHufv85M8EJzYOoPchh4QZDj26dWJl9fpd26uq13NwWcdQj9lSCvXcCvG8Tj9pAHMXf8KadZsBWLKsmnOvuhOAww7pxsivDowyvJQyHFixxt2HhRdNQovMNO7uG4CZfPFaGHef6O7D3H1Y17KuocYxdEAfPly+hmUra9ixs5Yp0ysZPeLoUI/ZUgr13ArxvM77xjAef6Fi13ZZ5/YAmBnXffcb/PXxV6MKLW25urTch2ozKwcIXlen+oPQamRm1hXY6e4bzKwdcDrwq7COl46SkmJuu+ECzr36TurqnEvOOoEjDyuPMqScKdRzK7TzardfKaccdwTX/vKhXfvO/cYwvnfeCACenvkODzw1K6rw0hby5f00YCyJGcfHAlNTxtNYG0QumNnRJBrqiknU/Ca7+61N/c2xxw7z12bPCSUekUx0/sqVUYcQis/fm0z91tVZpaGjhxzrz/zj9bQ+e8hBbSuaurQ0s4eAU4AyoBr4OfAkMBk4BFgOnO/ue98Q2ENoNTJ3nwccE1b5IhIRy12NzN0v3sdbGXWma3U9+0UkF/Lr1rESmYhkRAMrikhByLe+fEpkIpIxDawoIvGXX3lMiUxEMpdneUyJTEQyYznsfpErSmQikjHLs0ymRCYiGcuvNKZEJiLNkGcVMiUyEclUViNbhEKJTEQykuF4ZC1CiUxEMqZEJiKxp0tLEYk39SMTkbhLf6a3lqNEJiKZy7NMpkQmIhlTG5mIxF6+DazYItPBiUiBsTSXVMWYjTKz98zsAzMb39xwlMhEJGO5mNfSzIqBO4HRwADgYjMb0Jx4lMhEJCMNPfvTWVI4DvjA3T9y9x3Aw8CY5sSUV21klZUVNe1KbVkLHa4MqGmhY7UknVf8tOS59cm2gMrKiufblVpZmh9va2bJk9VOdPeJwXpP4JOk91YAxzcnprxKZO7etaWOZWZzmpo4NK50XvETt3Nz91E5KqqxOluzZgzXpaWIRGUF0DtpuxewqjkFKZGJSFTeAvqbWT8zawNcBExrTkF5dWnZwiam/kgs6bzip5DPbZ/cvdbMrgSeB4qBe919QXPKMvdmXZKKiOQNXVqKSOwpkYlI7LW6RJarRyLyjZnda2arzWx+1LHkkpn1NrOXzGyRmS0ws2uijikXzKytmb1pZnOD87ol6pjirFW1kQWPRLwPnEHi1u9bwMXuvjDSwHLAzEYAW4D73f2oqOPJFTMrB8rdvdLMDgQqgLPj/p1ZYmLIA9x9i5mVAq8C17j7rIhDi6XWViPL2SMR+cbdXwbWRR1Hrrl7lbtXBuubgUUkeoTHmidsCTZLg6X11CpyrLUlssYeiYj9/ylaCzPrCxwDzI44lJwws2IzewdYDUx394I4ryi0tkSWs0cipGWZWXvgceDH7r4p6nhywd3r3H0IiR7tx5lZwTQJtLTWlshy9kiEtJygDelx4AF3nxJ1PLnm7huAmUCunmFsdVpbIsvZIxHSMoJG8XuARe7+26jjyRUz62pmnYL1dsDpwOJIg4qxVpXI3L0WaHgkYhEwubmPROQbM3sIeAM43MxWmNkVUceUI8OBS4FTzeydYDkz6qByoBx4yczmkfgHdrq7Px1xTLHVqrpfiEhhalU1MhEpTEpkIhJ7SmQiEntKZCISe0pkIhJ7SmQxYmZ1QfeD+Wb2qJntn0VZ95nZecH63U3NJ2hmp5jZSc04xlKzL862s6/9e31mS1PvN/L5/zSz6zKNUQqDElm8bHP3IcHoFjuAHyS/GYzukTF3/16K0SROATJOZCItRYksvl4BvhTUll4ysweBd4MHkX9tZm+Z2Twz+z4kesib2R/MbKGZPQN0ayjIzGaa2bBgfZSZVQbjZM0IHtT+AXBtUBv8WtAr/fHgGG+Z2fDgbw8ysxfM7G0z+zONP9u6BzN70swqgjG5xu313u1BLDPMrGuw7zAzey74m1fM7Iic/NeUeHN3LTFZgC3BawkwFfg3ErWlz4B+wXvjgJuC9f2AOUA/4BxgOolJHnoAG4Dzgs/NBIYBXUmMDtJQVpfg9T+B65LieBD4arB+CInHhwD+F7g5WP8miQfyyxo5j6UN+5OO0Q6YDxwUbDtwSbB+M/CHYH0G0D9YPx74R2MxamldS2ueRSmO2gXDvkCiRnYPiUu+N93942D/SODohvYvoCPQHxgBPOTudcAqM/tHI+WfALzcUJa772t8s9OBAYnHIAHoEAx6OIJEwsTdnzGz9Wmc09Vm9q1gvXcQ61qgHngk2P93YEowAsZJwKNJx94vjWNIgVMii5dtnhj2ZZfg/9CfJe8CrnL35/f63JmkHrLI0vgMJJokTnT3bY3EkvYzb2Z2ComkeKK7bzWzmUDbfXzcg+Nu2Pu/gYjayArP88C/BUPfYGZfNrMDgJeBi4I2tHLg64387RvAyWbWL/jbLsH+zcCBSZ97gcTD9wSfGxKsvgxcEuwbDXROEWtHYH2QxI4gUSNsUAQ01Cq/DbzqiXHIPjaz84NjmJkNTnEMaQWUyArP3cBCoNISE5H8mUTN+wlgCfAucBfwz73/0N3XkGhjm2Jmc9l9afcU8K2Gxn7gamBYcDNhIbvvnt4CjDCzShKXuMtTxPocUBKMAPELIHm8+s+AgWZWAZwK3BrsvwS4IohvAQUyVLlkR6NfiEjsqUYmIrGnRCYisadEJiKxp0QmIrGnRCYisadEJiKxp0QmIrH3/wFn0Sc5TrbyqgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp = plot_confusion_matrix(classifier, X_pred, Y_test.argmax(axis=1),\n",
    "                                 #display_labels=class_names,\n",
    "                                 cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "475d570e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0 137  49  79]\n",
      "[ 0 53 43 79]\n",
      "[ 0 84  6  0]\n"
     ]
    }
   ],
   "source": [
    "print(cnf_matrix.sum(axis=0))\n",
    "print(np.diag(cnf_matrix) )\n",
    "print(cnf_matrix.sum(axis=0) - np.diag(cnf_matrix) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8088eb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camii\\AppData\\Local\\Temp/ipykernel_14012/1338496663.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  PPV = TP/(TP+FP)\n",
      "C:\\Users\\camii\\AppData\\Local\\Temp/ipykernel_14012/1338496663.py:22: RuntimeWarning: invalid value encountered in true_divide\n",
      "  FDR = FP/(TP+FP)\n"
     ]
    }
   ],
   "source": [
    "FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix) \n",
    "FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "TP = np.diag(cnf_matrix)\n",
    "TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "# Overall accuracy for each class\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3eb60beb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000        65\n",
      "           1      0.387     0.898     0.541        59\n",
      "           2      0.878     0.694     0.775        62\n",
      "           3      1.000     1.000     1.000        79\n",
      "\n",
      "    accuracy                          0.660       265\n",
      "   macro avg      0.566     0.648     0.579       265\n",
      "weighted avg      0.590     0.660     0.600       265\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camii\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\camii\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\camii\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Print the precision and recall, among other metrics\n",
    "print(classification_report(Test_Y_final, predicted_labels, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d83bd8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9647c6be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
