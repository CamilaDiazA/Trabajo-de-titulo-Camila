{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86b7de23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from skimage.color import (separate_stains, combine_stains,\n",
    "                            hdx_from_rgb, rgb_from_hdx,rgb2hed, hed2rgb) \n",
    "from skimage.exposure import rescale_intensity\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.metrics import precision_score,recall_score,accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a69f7a",
   "metadata": {},
   "source": [
    "# Funciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aa247cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leer el conjunto de imagenes\n",
    "def LeerImagenes(imagenes):\n",
    "    imgs=[]\n",
    "    for x in range(0,len(imagenes)):\n",
    "        imgs.append(io.imread(imagenes[x]))\n",
    "    MImagenes=np.array(imgs)\n",
    "    \n",
    "    return MImagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51c18014",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crea matriz con las etiquetas de las imagenes\n",
    "def CalculoEtiquetas(imagenes):\n",
    "    Etiquetas=[]\n",
    "    for x in range(0,len(imagenes)):\n",
    "        Clasificacion =imagenes[x].split('-') \n",
    "        for i in range(0,len(Clasificacion)) :\n",
    "            Valores=(Clasificacion[2])\n",
    "            Numero=Valores.split('_')\n",
    "        Etiquetas.append(int(Numero[1]))\n",
    "        #Etiquetas=np.array(etiquetas)\n",
    "    return Etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e98f9713",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplico filtro al conjunto de imagenes ingresados cono paramentro\n",
    "def AplicarFiltro(MImagenes):\n",
    "    imgs_con_filtro=[]\n",
    "    for x in range(0,len(MImagenes)):\n",
    "        ihc_hdx = rgb2hed(MImagenes[x])\n",
    "        null = np.zeros_like(ihc_hdx[:, :, 0])\n",
    "        ihc_h = hed2rgb(np.stack((ihc_hdx[:, :, 0], null, null), axis=-1))\n",
    "        ihc_d = hed2rgb(np.stack((null, ihc_hdx[:, :, 1], null), axis=-1))\n",
    "        ihc_x = hed2rgb(np.stack((null, null, ihc_hdx[:, :, 2]), axis=-1))\n",
    "\n",
    "        h = rescale_intensity(ihc_hdx[:, :, 0], out_range=(0, 1),\n",
    "                      in_range=(0, np.percentile(ihc_hdx[:, :, 0], 99)))\n",
    "        d = rescale_intensity(ihc_hdx[:, :, 2], out_range=(0, 1),\n",
    "                      in_range=(0, np.percentile(ihc_hdx[:, :, 2], 99)))\n",
    "    \n",
    "        zdh = np.dstack((null, d, h))\n",
    "        imgs_con_filtro.append(zdh)\n",
    "    Imagenes_con_fitro=np.array(imgs_con_filtro)\n",
    "    return Imagenes_con_fitro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcc331ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtiene el canal DAB de las imagenes representativas ingresadas\n",
    "def ImagenDAB(MImagenes):\n",
    "    imgs_DAB=[]\n",
    "    for x in range(0,len(MImagenes)):\n",
    "        ihc_hdx = rgb2hed(MImagenes[x])\n",
    "        null = np.zeros_like(ihc_hdx[:, :, 0])\n",
    "        #Seleccionó solo el canal DAB\n",
    "        ihc_x = hed2rgb(np.stack((null, null, ihc_hdx[:, :, 2]), axis=-1)) \n",
    "        #Guardo solo el canal DAB \n",
    "        imgs_DAB.append(ihc_x)\n",
    "    Imagenes_DAB=np.array(imgs_DAB)\n",
    "    return Imagenes_DAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "137e4042",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtiene los valores promedios de cada clase y los valores min y max de estos, segun las imagenes representativas ingresadas\n",
    "\n",
    "def CalculoPromedios(Imagenes_DAB,Etiquetas):\n",
    "    Prom0=[]\n",
    "    Prom1=[]\n",
    "    Prom2=[]\n",
    "    Prom3=[]\n",
    "    Prom_imgs=[]\n",
    "    for x in range(0,len(Imagenes_DAB)):\n",
    "        Promedio=np.mean(Imagenes_DAB[x])\n",
    "        Prom_imgs.append(Promedio)\n",
    "    for x in range(0,len(Etiquetas)):\n",
    "        if Etiquetas[x]==0:\n",
    "            Prom0.append(Prom_imgs[x])\n",
    "        elif Etiquetas[x]==1:\n",
    "            Prom1.append(Prom_imgs[x])\n",
    "        elif Etiquetas[x]==2:\n",
    "            Prom2.append(Prom_imgs[x])\n",
    "        elif Etiquetas[x]==3:   \n",
    "            Prom3.append(Prom_imgs[x])\n",
    "        else:\n",
    "            print(\"Error en la etiqueta\") \n",
    "    Min0=min(Prom0)        \n",
    "    Max0=max(Prom0)\n",
    "    Min1=min(Prom1)\n",
    "    Max1=max(Prom1)\n",
    "    Min2=min(Prom2)\n",
    "    Max2=max(Prom2)\n",
    "    Min3=min(Prom3)\n",
    "    Max3=max(Prom3)\n",
    "    return Min0,Max0,Min1,Max1,Min2,Max2,Min3,Max3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f2e341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtra, quitando las imagenes que no cumplan con los valores asignados para su clase, retornando el conjunto de imagenes que \n",
    "#cumplen con los requisitos\n",
    "\n",
    "def SemiFiltro(Imagenes,Etiquetas,Min0,Max0,Min1,Max1,Min2,Max2,Min3,Max3):\n",
    "    Imgs=[]\n",
    "    etqs=[]\n",
    "    Imgs_DAB=ImagenDAB(Imagenes)\n",
    "            \n",
    "    for x in range(0,len(Imagenes)):\n",
    "        Promedio=np.mean(Imgs_DAB[x])\n",
    "        if Etiquetas[x]==0:\n",
    "            if Promedio>=Min0 and Promedio<=Max0:\n",
    "                Imgs.append(Imagenes[x])\n",
    "                etqs.append(Etiquetas[x])\n",
    "        elif Etiquetas[x]==1:\n",
    "            if Promedio>=Min1 and Promedio<=Max1:\n",
    "                Imgs.append(Imagenes[x])\n",
    "                etqs.append(Etiquetas[x])\n",
    "        elif Etiquetas[x]==2:\n",
    "            if Promedio>=Min2 and Promedio<=Max2:\n",
    "                Imgs.append(Imagenes[x])\n",
    "                etqs.append(Etiquetas[x])\n",
    "        elif Etiquetas[x]==3:   \n",
    "            if Promedio>=Min3 and Promedio<=Max3:\n",
    "                Imgs.append(Imagenes[x])\n",
    "                etqs.append(Etiquetas[x])\n",
    "        else:\n",
    "            print(\"Error en la etiqueta\")\n",
    "    Imagenes=np.array(Imgs)\n",
    "    Etqs=np.array(etqs)\n",
    "    return Imagenes,Etqs             \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a730a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constantes\n",
    "data_source = \"../data(1000)/\"\n",
    "models_dir = '../saved_models/'\n",
    "train_imgs = glob(f\"{data_source}training/*.png\")\n",
    "test_imgs = glob(f\"{data_source}test/*.png\")\n",
    "I_representativas=glob(f\"{data_source}Imagenes_representativas/*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52f27d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#leer imagenes\n",
    "Imagenes_rep=LeerImagenes(I_representativas)\n",
    "Etiquetas_rep=CalculoEtiquetas(I_representativas)\n",
    "X_train=LeerImagenes(train_imgs)\n",
    "y_train=CalculoEtiquetas(train_imgs)\n",
    "X_test=LeerImagenes(test_imgs)\n",
    "y_test=CalculoEtiquetas(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "512940f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImagenesDAB=ImagenDAB(Imagenes_rep)\n",
    "Min0,Max0,Min1,Max1,Min2,Max2,Min3,Max3=CalculoPromedios(ImagenesDAB,Etiquetas_rep)\n",
    "Train_X_final,Train_Y_final=SemiFiltro(X_train,y_train,Min0,Max0,Min1,Max1,Min2,Max2,Min3,Max3)\n",
    "Test_X_final,Test_Y_final=SemiFiltro(X_test,y_test,Min0,Max0,Min1,Max1,Min2,Max2,Min3,Max3)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1684417d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n",
      "1143\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(Train_X_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1aebbb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 4\n",
    "Y_train = np_utils.to_categorical(Train_Y_final, n_classes)\n",
    "Y_test = np_utils.to_categorical(Test_Y_final, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dfb443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X_F=AplicarFiltro(Train_X_final)\n",
    "Test_X_F=AplicarFiltro(Test_X_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d76163",
   "metadata": {},
   "source": [
    "# Creación de CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe9c4867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 73, 73, 96)        34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 73, 73, 96)        384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 36, 36, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 36, 36, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 36, 36, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 17, 17, 384)       885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 17, 17, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 17, 17, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 17, 17, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 17, 17, 256)       884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 17, 17, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              67112960  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 16388     \n",
      "=================================================================\n",
      "Total params: 87,663,364\n",
      "Trainable params: 87,660,612\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(300,300,3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c4b7ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"logs\\\\fit\\\\\")\n",
    "def get_run_logdir():\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "run_logdir = get_run_logdir()\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a63d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=tf.optimizers.SGD(lr=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb941590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 1/36 [..............................] - ETA: 0s - loss: 3.8030 - accuracy: 0.1875WARNING:tensorflow:From C:\\Users\\camii\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "36/36 [==============================] - 65s 2s/step - loss: 1.5936 - accuracy: 0.6063 - val_loss: 1.4557 - val_accuracy: 0.2226\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.9902 - accuracy: 0.7323 - val_loss: 1.7932 - val_accuracy: 0.2226\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.5823 - accuracy: 0.8303 - val_loss: 2.3730 - val_accuracy: 0.3509\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.6306 - accuracy: 0.8119 - val_loss: 3.0692 - val_accuracy: 0.4415\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 63s 2s/step - loss: 0.5237 - accuracy: 0.8364 - val_loss: 3.6928 - val_accuracy: 0.4415\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 62s 2s/step - loss: 0.4792 - accuracy: 0.8478 - val_loss: 4.0537 - val_accuracy: 0.4604\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.4197 - accuracy: 0.8635 - val_loss: 4.3578 - val_accuracy: 0.4491\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.2895 - accuracy: 0.9020 - val_loss: 4.7617 - val_accuracy: 0.4566\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.2938 - accuracy: 0.9003 - val_loss: 4.9157 - val_accuracy: 0.4264\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.3075 - accuracy: 0.8985 - val_loss: 5.2675 - val_accuracy: 0.4453\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.2406 - accuracy: 0.9125 - val_loss: 5.3042 - val_accuracy: 0.4566\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.2735 - accuracy: 0.9073 - val_loss: 4.9403 - val_accuracy: 0.4415\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.2175 - accuracy: 0.9239 - val_loss: 5.1083 - val_accuracy: 0.4264\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.2085 - accuracy: 0.9204 - val_loss: 3.4094 - val_accuracy: 0.4642\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 61s 2s/step - loss: 0.2133 - accuracy: 0.9256 - val_loss: 3.5901 - val_accuracy: 0.4679\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.1636 - accuracy: 0.9449 - val_loss: 3.1205 - val_accuracy: 0.5094\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.1505 - accuracy: 0.9431 - val_loss: 3.0699 - val_accuracy: 0.5094\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.1437 - accuracy: 0.9440 - val_loss: 0.9631 - val_accuracy: 0.7170\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.1316 - accuracy: 0.9484 - val_loss: 0.4949 - val_accuracy: 0.8189\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 65s 2s/step - loss: 0.1394 - accuracy: 0.9510 - val_loss: 0.9147 - val_accuracy: 0.8151\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.1295 - accuracy: 0.9493 - val_loss: 0.2394 - val_accuracy: 0.9019\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.1010 - accuracy: 0.9589 - val_loss: 0.4299 - val_accuracy: 0.8642\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.1170 - accuracy: 0.9563 - val_loss: 0.1714 - val_accuracy: 0.9472\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.0772 - accuracy: 0.9729 - val_loss: 0.2955 - val_accuracy: 0.9057\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.0865 - accuracy: 0.9720 - val_loss: 0.2771 - val_accuracy: 0.9019\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.1009 - accuracy: 0.9659 - val_loss: 0.5124 - val_accuracy: 0.8604\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.0723 - accuracy: 0.9746 - val_loss: 0.2676 - val_accuracy: 0.9094\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.0757 - accuracy: 0.9694 - val_loss: 0.2987 - val_accuracy: 0.9019\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.0727 - accuracy: 0.9729 - val_loss: 0.2971 - val_accuracy: 0.8981\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.0670 - accuracy: 0.9764 - val_loss: 0.4112 - val_accuracy: 0.8566\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.0656 - accuracy: 0.9703 - val_loss: 0.2519 - val_accuracy: 0.9245\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.0565 - accuracy: 0.9825 - val_loss: 0.8583 - val_accuracy: 0.8377\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.0759 - accuracy: 0.9703 - val_loss: 0.6023 - val_accuracy: 0.8566\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.0591 - accuracy: 0.9799 - val_loss: 0.5859 - val_accuracy: 0.8604\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.0617 - accuracy: 0.9746 - val_loss: 0.2424 - val_accuracy: 0.9283\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.0402 - accuracy: 0.9869 - val_loss: 0.4266 - val_accuracy: 0.8755\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.0658 - accuracy: 0.9781 - val_loss: 0.3424 - val_accuracy: 0.9019\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.0572 - accuracy: 0.9790 - val_loss: 0.3214 - val_accuracy: 0.9094\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.0517 - accuracy: 0.9799 - val_loss: 0.2312 - val_accuracy: 0.9396\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.0379 - accuracy: 0.9869 - val_loss: 0.2203 - val_accuracy: 0.9434\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 65s 2s/step - loss: 0.0371 - accuracy: 0.9843 - val_loss: 0.5219 - val_accuracy: 0.8642\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.0413 - accuracy: 0.9851 - val_loss: 0.3570 - val_accuracy: 0.9019\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.0289 - accuracy: 0.9886 - val_loss: 0.3989 - val_accuracy: 0.8868\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.0285 - accuracy: 0.9904 - val_loss: 0.2480 - val_accuracy: 0.9019\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.0354 - accuracy: 0.9886 - val_loss: 0.2661 - val_accuracy: 0.9208\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.0336 - accuracy: 0.9869 - val_loss: 0.2447 - val_accuracy: 0.9358\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.0246 - accuracy: 0.9913 - val_loss: 0.3021 - val_accuracy: 0.9132\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.0398 - accuracy: 0.9834 - val_loss: 0.5573 - val_accuracy: 0.8604\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.0304 - accuracy: 0.9886 - val_loss: 0.2360 - val_accuracy: 0.9208\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.0324 - accuracy: 0.9895 - val_loss: 0.7277 - val_accuracy: 0.7887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2cda3701d60>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Train_X_F, Y_train, epochs=50,validation_data=(Test_X_F, Y_test),validation_freq = 1,callbacks = [tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2066f463",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred=model.predict(Test_X_F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0088686",
   "metadata": {},
   "source": [
    "# Evaluación \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30bf7fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[65  0  0  0]\n",
      " [10 31  3 15]\n",
      " [ 0 10 34 18]\n",
      " [ 0  0  0 79]]\n"
     ]
    }
   ],
   "source": [
    "cnf_matrix = confusion_matrix(Y_test.argmax(axis=1), Y_test.argmax(axis=1))\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb3d1d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp = plot_confusion_matrix(classifier, X_pred, Y_test.argmax(axis=1),\n",
    "                                 #display_labels=class_names,\n",
    "                                 cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7406c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 75  41  37 112]\n",
      "[65 31 34 79]\n",
      "[10 10  3 33]\n"
     ]
    }
   ],
   "source": [
    "print(cnf_matrix.sum(axis=0))\n",
    "print(np.diag(cnf_matrix) )\n",
    "print(cnf_matrix.sum(axis=0) - np.diag(cnf_matrix) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba22c7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix) \n",
    "FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "TP = np.diag(cnf_matrix)\n",
    "TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "# Overall accuracy for each class\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b0ab685e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.867     1.000     0.929        65\n",
      "           1      0.756     0.525     0.620        59\n",
      "           2      0.919     0.548     0.687        62\n",
      "           3      0.705     1.000     0.827        79\n",
      "\n",
      "    accuracy                          0.789       265\n",
      "   macro avg      0.812     0.768     0.766       265\n",
      "weighted avg      0.806     0.789     0.773       265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the precision and recall, among other metrics\n",
    "print(classification_report(Test_Y_final, predicted_labels, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a39a00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
